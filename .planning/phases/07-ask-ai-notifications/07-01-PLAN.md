---
phase: 07-ask-ai-notifications
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/components/chat/memoized-markdown.tsx
  - src/components/chat/chat-message.tsx
  - src/components/chat/ask-ai-panel.tsx
  - src/components/chat/conversation-list.tsx
  - src/components/chat/ask-ai-global-trigger.tsx
  - src/app/api/chat/route.ts
  - src/app/api/conversations/route.ts
  - src/app/api/conversations/[id]/route.ts
  - src/app/(wiki)/layout.tsx
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User can open a global Ask AI panel from any page via a header button"
    - "User sends a message and receives a streaming Markdown response"
    - "Conversations are persisted per user in ai_conversations + ai_conversation_messages"
    - "User can continue a previous conversation, start a new one, or delete conversations"
    - "Global Ask AI receives the article index (titles, slugs, descriptions) as context"
  artifacts:
    - path: "src/components/chat/memoized-markdown.tsx"
      provides: "Streaming-safe memoized markdown renderer using marked.lexer + react-markdown"
      exports: ["MemoizedMarkdown"]
    - path: "src/components/chat/chat-message.tsx"
      provides: "Single chat message component with role styling and memoized markdown"
      exports: ["ChatMessage"]
    - path: "src/components/chat/ask-ai-panel.tsx"
      provides: "Sheet-based chat UI with message list, input, streaming status"
      exports: ["AskAiPanel"]
    - path: "src/components/chat/conversation-list.tsx"
      provides: "Previous conversations list with select, new, delete"
      exports: ["ConversationList"]
    - path: "src/components/chat/ask-ai-global-trigger.tsx"
      provides: "Header button that opens the global Ask AI panel"
      exports: ["AskAiGlobalTrigger"]
    - path: "src/app/api/chat/route.ts"
      provides: "POST streaming endpoint for global Ask AI"
      exports: ["POST"]
    - path: "src/app/api/conversations/route.ts"
      provides: "GET list + POST create + DELETE conversation"
      exports: ["GET", "POST"]
    - path: "src/app/api/conversations/[id]/route.ts"
      provides: "GET single conversation with messages, DELETE single conversation"
      exports: ["GET", "DELETE"]
  key_links:
    - from: "src/components/chat/ask-ai-panel.tsx"
      to: "/api/chat"
      via: "useChat with DefaultChatTransport"
      pattern: "DefaultChatTransport.*api.*chat"
    - from: "src/components/chat/ask-ai-panel.tsx"
      to: "/api/conversations"
      via: "fetch for conversation CRUD"
      pattern: "fetch.*api/conversations"
    - from: "src/app/api/chat/route.ts"
      to: "ai_conversations + ai_conversation_messages"
      via: "drizzle insert on stream finish"
      pattern: "aiConversationMessages"
    - from: "src/app/(wiki)/layout.tsx"
      to: "src/components/chat/ask-ai-global-trigger.tsx"
      via: "imported in header"
      pattern: "AskAiGlobalTrigger"
---

<objective>
Build the global Ask AI chat panel with streaming Markdown responses and full conversation persistence.

Purpose: Users can ask AI questions about the wiki from any page, with streaming responses and the ability to manage conversation history.
Output: Shared chat components, global streaming API route, conversation CRUD API, header trigger button.
</objective>

<execution_context>
@/Users/michael/.claude/get-shit-done/workflows/execute-plan.md
@/Users/michael/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-ask-ai-notifications/07-RESEARCH.md
@src/lib/db/schema.ts
@src/lib/ai/client.ts
@src/lib/ai/analyze.ts
@src/lib/settings/constants.ts
@src/app/(wiki)/layout.tsx
@src/components/ui/sheet.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install marked, create shared chat components, and global streaming API route</name>
  <files>
    src/components/chat/memoized-markdown.tsx
    src/components/chat/chat-message.tsx
    src/components/chat/ask-ai-panel.tsx
    src/app/api/chat/route.ts
  </files>
  <action>
**Step 1: Install marked**
```bash
npm install marked && npm install --save-dev @types/marked
```

**Step 2: Create `src/components/chat/memoized-markdown.tsx`**
Streaming-safe markdown renderer. Use `marked.lexer()` to split markdown into blocks, wrap each block in `React.memo` with `react-markdown`. Pattern from research:
- `parseMarkdownIntoBlocks(markdown: string): string[]` using `marked.lexer` -> map to `token.raw`
- `MemoizedMarkdownBlock` = `memo(({ content }) => <ReactMarkdown>{content}</ReactMarkdown>)` with content equality check
- `MemoizedMarkdown` = `memo(({ content, id }) => ...)` that splits into blocks via `useMemo`, maps blocks to `MemoizedMarkdownBlock` with key `{id}-block_{index}`
- Export `MemoizedMarkdown`

**Step 3: Create `src/components/chat/chat-message.tsx`**
"use client" component. Props: `{ message: { id: string; role: 'user' | 'assistant'; content: string } }`.
- User messages: right-aligned, primary background, white text
- Assistant messages: left-aligned, muted background, uses `MemoizedMarkdown` for content rendering
- Show role label above each message (small text)
- Wrap in `memo` for performance

**Step 4: Create `src/components/chat/ask-ai-panel.tsx`**
"use client" component. This is the shared chat UI used by both global and page-level Ask AI. Props:
```typescript
interface AskAiPanelProps {
  open: boolean;
  onOpenChange: (open: boolean) => void;
  endpoint: string; // '/api/chat' or '/api/chat/article'
  title: string;
  articleId?: string; // only for page-level
  contextIndicator?: React.ReactNode; // only for page-level
}
```
Implementation:
- Uses `Sheet` from `@/components/ui/sheet` (side="right", large width e.g. `sm:max-w-lg`)
- State: `conversationId` (string | null), `conversations` list, `initialMessages` (UIMessage[])
- On open: fetch `GET /api/conversations?mode=global` (or `?mode=page&articleId=X`) to get conversation list
- `useChat` from `@ai-sdk/react` with:
  - `id: conversationId`
  - `messages: initialMessages`
  - `transport: new DefaultChatTransport({ api: endpoint, prepareSendMessagesRequest: ... })` -- send `conversationId`, `message` (latest only), and optionally `articleId` in body
  - `experimental_throttle: 50`
  - `onError: () => toast.error('Failed to get AI response')`
- `prepareSendMessagesRequest` sends only the last message + conversationId + articleId (if present)
- Message list area: scrollable div with auto-scroll to bottom, map messages rendering `ChatMessage` for each. Show empty state when no messages ("Ask me anything about the wiki...")
- Input area at bottom: text input + Send button (lucide `Send` icon). Call `sendMessage({ text: inputValue })` on submit. Disable while `status === 'streaming'`. Show `stop()` button while streaming.
- Conversation management UI at top of sheet (below title):
  - `ConversationList` component (built in next task) for selecting/creating/deleting conversations
  - "New Conversation" button: sets conversationId to null, clears messages

**Important:** When `conversationId` is null and user sends first message, the API route creates the conversation and returns the ID. The client needs to capture this. Use the `onFinish` callback or read from the response headers/body. Approach: the POST /api/chat route will include `conversationId` in a custom header `X-Conversation-Id`. After `useChat` receives the first response, read the header via transport. Alternatively, simpler: before sending the first message, POST to `/api/conversations` to create the conversation, get the ID back, set it, then send the message. Use this approach -- it's cleaner.

So the flow for new conversations:
1. User types message, clicks send
2. If `conversationId` is null: POST `/api/conversations` with `{ mode: 'global' }` (or `{ mode: 'page', articleId }`) and `title` = first 80 chars of user message
3. Set conversationId from response
4. Then call `sendMessage()` which goes to the chat streaming endpoint

For continuing a conversation:
1. User selects from ConversationList
2. Fetch `GET /api/conversations/{id}` to load messages
3. Set `initialMessages` to loaded UIMessages (reconstruct from DB: `{ id, role, parts: [{ type: 'text', text: content }] }`)
4. Set `conversationId`
5. User sends message normally

**Step 5: Create `src/app/api/chat/route.ts`**
POST handler for global Ask AI streaming:
- Auth check (session required)
- Parse body: `{ conversationId: string, message: { role: 'user', parts: [{ type: 'text', text: string }] } }`
- Load prior messages from `ai_conversation_messages` where `conversationId` matches, ordered by `createdAt asc`
- Reconstruct UIMessage array from DB records (each: `{ id, role, parts: [{ type: 'text', text: content }] }`)
- Push the new user message onto the array
- Load system prompt from `getSetting(SETTING_KEYS.ask_ai_global_prompt)` -- use a sensible default if not configured: "You are a helpful assistant for the CodeWiki documentation system. Answer questions about the wiki articles, codebase, and documentation."
- Build context: call `getArticleIndex()` from `src/lib/ai/analyze.ts`, format as a list of articles with titles, slugs, categories, and whether they have human edits. Prefix with "## Available Wiki Articles\n\n"
- Get model via `getAIModel()`
- Call `streamText({ model, system: systemPrompt + '\n\n' + contextText, messages: await convertToModelMessages(allMessages), abortSignal: req.signal })`
- Call `result.consumeStream()` to ensure completion
- Return `result.toUIMessageStreamResponse({ onFinish: async ({ messages }) => { ... } })`
- In `onFinish`: save the new user message and assistant response to `ai_conversation_messages`. Extract content from messages: for each message, find the text part (`msg.parts?.find(p => p.type === 'text')?.text || msg.content`). Insert both the user message and assistant message. Also update `ai_conversations.updatedAt`.

Import from 'ai': `streamText`, `convertToModelMessages`, `UIMessage`.
  </action>
  <verify>
- `npm run build` succeeds (no type errors)
- `curl -X POST http://localhost:3000/api/chat -H 'Content-Type: application/json' -d '{"conversationId":"test","message":{"role":"user","parts":[{"type":"text","text":"hello"}]}}'` returns streaming response (will 401 without session, but confirms route exists)
  </verify>
  <done>
- MemoizedMarkdown renders streaming markdown without full re-render cascade
- ChatMessage displays user/assistant messages with appropriate styling
- AskAiPanel provides Sheet-based chat UI with useChat streaming
- POST /api/chat streams AI responses using article index as context and persists messages to DB
  </done>
</task>

<task type="auto">
  <name>Task 2: Conversation CRUD API, conversation list UI, and global trigger in header</name>
  <files>
    src/app/api/conversations/route.ts
    src/app/api/conversations/[id]/route.ts
    src/components/chat/conversation-list.tsx
    src/components/chat/ask-ai-global-trigger.tsx
    src/app/(wiki)/layout.tsx
  </files>
  <action>
**Step 1: Create `src/app/api/conversations/route.ts`**
- `GET`: Auth check. Query params: `mode` (global|page), `articleId` (optional, for page mode). Return `ai_conversations` for the current user filtered by mode (and articleId if page mode), ordered by `updatedAt desc`. Return `{ id, title, mode, articleId, updatedAt }[]`.
- `POST`: Auth check. Body: `{ mode: 'global' | 'page', articleId?: string, title: string }`. Insert into `ai_conversations` with userId from session. Return `{ id, title, mode }`.

**Step 2: Create `src/app/api/conversations/[id]/route.ts`**
- `GET`: Auth check. Fetch the conversation (verify userId matches session). Load all `ai_conversation_messages` for this conversation ordered by `createdAt asc`. Return `{ conversation: { id, title, mode, articleId }, messages: { id, role, content, createdAt }[] }`.
- `DELETE`: Auth check. Verify userId matches session. Delete the conversation (cascade deletes messages). Return 204.

**Step 3: Create `src/components/chat/conversation-list.tsx`**
"use client" component. Props:
```typescript
interface ConversationListProps {
  conversations: Array<{ id: string; title: string | null; updatedAt: string }>;
  activeConversationId: string | null;
  onSelect: (id: string) => void;
  onDelete: (id: string) => void;
  onNew: () => void;
}
```
- Render a compact list of conversations above the chat area. Each item shows title (or "Untitled" if null) and relative time. Active conversation highlighted.
- Each conversation has a small trash icon button for delete (with confirmation via window.confirm).
- "New Conversation" button at top with `Plus` icon from lucide.
- If no conversations, show "No previous conversations".

**Step 4: Create `src/components/chat/ask-ai-global-trigger.tsx`**
"use client" component. Renders:
- A button with `Sparkles` icon from lucide-react + "Ask AI" text
- State: `open` boolean controlling the AskAiPanel sheet
- Renders `<AskAiPanel open={open} onOpenChange={setOpen} endpoint="/api/chat" title="Ask AI" />`
- Export `AskAiGlobalTrigger`

**Step 5: Update `src/app/(wiki)/layout.tsx`**
- Import `AskAiGlobalTrigger` from `@/components/chat/ask-ai-global-trigger`
- Add `<AskAiGlobalTrigger />` in the header, between the `<Separator>` and the search input `<div>`. Position it after the separator and before the `ml-auto` search div. The layout becomes: SidebarTrigger | Separator | AskAiGlobalTrigger | [spacer] | SearchInput
- Update the flex layout: remove `ml-auto` from the search div, instead put `flex-1` on the gap div and `ml-auto` on a wrapper containing search. Or simpler: keep the existing flex layout, add the trigger button after the Separator, and keep search with `ml-auto`.
  </action>
  <verify>
- `npm run build` succeeds
- Visiting any wiki page shows "Ask AI" button in the header
- Clicking "Ask AI" opens a slide-out panel
- Sending a message streams an AI response
- Closing and reopening shows the conversation was persisted
- "New Conversation" starts fresh; selecting a previous conversation loads its messages
- Delete removes a conversation from the list
  </verify>
  <done>
- Conversation CRUD API routes support list, create, get-with-messages, and delete
- ConversationList UI shows previous conversations with select/new/delete
- AskAiGlobalTrigger button appears in wiki header on every page
- Full global Ask AI flow works: open panel -> send message -> see streaming response -> conversation persisted -> can continue/start new/delete
- Requirements satisfied: ASKI-01, ASKI-02, ASKI-04, ASKI-05, ASKI-06
  </done>
</task>

</tasks>

<verification>
1. Open any wiki page -- "Ask AI" button visible in header (ASKI-01)
2. Click "Ask AI" -- slide-out panel opens
3. Type a question about the wiki and send -- streaming markdown response appears (ASKI-04)
4. Close panel, reopen -- conversation persisted and visible in conversation list (ASKI-05)
5. Click "New Conversation" -- starts fresh conversation
6. Select previous conversation -- loads its messages, can continue chatting (ASKI-06)
7. Delete a conversation -- removed from list (ASKI-06)
8. Check DB: ai_conversations and ai_conversation_messages have records for user
</verification>

<success_criteria>
- Global Ask AI accessible from header on every wiki page (ASKI-01)
- Article index provided as context to AI (ASKI-02) -- verifiable by asking "list the wiki articles"
- Streaming markdown responses render progressively without flickering (ASKI-04)
- Conversations persist in DB per user (ASKI-05)
- User can continue, start new, or delete conversations (ASKI-06)
</success_criteria>

<output>
After completion, create `.planning/phases/07-ask-ai-notifications/07-01-SUMMARY.md`
</output>

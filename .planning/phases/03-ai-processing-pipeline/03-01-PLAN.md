---
phase: 03-ai-processing-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/ai/client.ts
  - src/lib/ai/schemas.ts
  - src/lib/ai/prompts.ts
  - src/lib/ai/analyze.ts
  - src/lib/ai/generate.ts
autonomous: true

must_haves:
  truths:
    - "OpenRouter AI client reads API key and model name from site_settings"
    - "AI analysis receives changed file contents, full category tree, and article index as context"
    - "AI returns structured JSON defining which articles to create or update"
    - "AI-generated article content follows the admin-configured article style prompt"
    - "AI suggests categories for articles, preferring existing categories over new ones"
    - "File content is fetched from GitHub for changed files using Octokit"
  artifacts:
    - path: "src/lib/ai/client.ts"
      provides: "OpenRouter AI model factory using Vercel AI SDK + provider"
      exports: ["getAIModel"]
    - path: "src/lib/ai/schemas.ts"
      provides: "Zod schemas for structured AI output (analysis response, article plan)"
      exports: ["analysisResponseSchema"]
    - path: "src/lib/ai/prompts.ts"
      provides: "Prompt template builders for analysis and article generation"
      exports: ["buildAnalysisPrompt", "buildGenerationPrompt"]
    - path: "src/lib/ai/analyze.ts"
      provides: "Code analysis: changed files + context -> article plan"
      exports: ["analyzeChanges", "fetchFileContents"]
    - path: "src/lib/ai/generate.ts"
      provides: "Article generation: plan item -> markdown content with technical view"
      exports: ["generateArticle"]
  key_links:
    - from: "src/lib/ai/client.ts"
      to: "src/lib/settings/index.ts"
      via: "getSetting for openrouter_api_key and openrouter_model"
      pattern: "getSetting.*openrouter"
    - from: "src/lib/ai/analyze.ts"
      to: "src/lib/ai/client.ts"
      via: "getAIModel() for LLM calls"
      pattern: "getAIModel"
    - from: "src/lib/ai/analyze.ts"
      to: "@octokit/rest"
      via: "getOctokit + repos.getContent for file content fetching"
      pattern: "repos\\.getContent|getOctokit"
    - from: "src/lib/ai/prompts.ts"
      to: "src/lib/settings/index.ts"
      via: "getSetting for analysis_prompt and article_style_prompt"
      pattern: "getSetting.*(analysis_prompt|article_style_prompt)"
---

<objective>
Build the AI client, structured output schemas, prompt builders, code analysis, and article generation modules.

Purpose: This is the foundation of the AI pipeline -- the ability to send code to an LLM via OpenRouter and receive structured article plans back. It also fetches actual file content from GitHub (Phase 2 only stored SHA metadata).

Output: Five library files in `src/lib/ai/` that can analyze code changes and generate article content.
</objective>

<execution_context>
@/Users/michael/.claude/get-shit-done/workflows/execute-plan.md
@/Users/michael/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-processing-pipeline/03-RESEARCH.md
@src/lib/db/schema.ts
@src/lib/settings/index.ts
@src/lib/settings/constants.ts
@src/lib/github/client.ts
@src/lib/github/sync.ts
@docs/ultrawiki-spec.md (sections 6 and 7)
</context>

<tasks>

<task type="auto">
  <name>Task 1: AI client, Zod schemas, and prompt builders</name>
  <files>src/lib/ai/client.ts, src/lib/ai/schemas.ts, src/lib/ai/prompts.ts</files>
  <action>
Install dependencies: `npm install ai @openrouter/ai-sdk-provider` (add types if needed).

**src/lib/ai/client.ts** -- OpenRouter model factory:
- Export `getAIModel()` async function that reads `openrouter_api_key` and `openrouter_model` from site_settings via `getSetting()` (reuse existing settings library pattern).
- Use `createOpenRouter({ apiKey, headers: { "HTTP-Referer": "https://codewiki.internal", "X-Title": "CodeWiki" } })` from `@openrouter/ai-sdk-provider`.
- Return `openrouter(modelName)` -- the callable model instance.
- Throw descriptive errors if API key or model name not configured.

**src/lib/ai/schemas.ts** -- Zod schemas for structured AI output:
- Import from `zod/v4` (project convention from 01-03 decision).
- Export `analysisResponseSchema`: z.object with `articles` array containing objects with: `slug` (string), `title` (string), `action` (z.enum ["create", "update"]), `content_markdown` (string), `technical_view_markdown` (string), `change_summary` (string), `related_files` (z.array of string), `related_db_tables` (z.array of z.object with table_name, columns as z.record(z.string()).nullable(), relevance), `category_suggestion` (string), `conflicts_with_human_edits` (z.array of string).
- Also export the inferred TypeScript type `AnalysisResponse` from the schema.
- Export `summary` field (string) at the top level of the response.
- If Zod v4 causes issues with AI SDK v6, wrap with `import { zodSchema } from 'ai'` per research recommendation.

**src/lib/ai/prompts.ts** -- Prompt template builders:
- Export `buildAnalysisPrompt(ctx: PromptContext)` that assembles the full analysis prompt from:
  - The admin-configured `analysis_prompt` from site_settings (or a sensible default from the spec if not set)
  - `existingCategories` array rendered as a tree: `- ParentName > CategoryName (slug: xxx)` or `- CategoryName (slug: xxx)` for root categories
  - `existingArticles` array rendered as index: `- [CategoryName] "Title" (slug: xxx) [HUMAN-EDITED]` flag if hasHumanEdits
  - The admin-configured `article_style_prompt` from site_settings
  - `changedFiles` array rendered as `### path/to/file\n```\ncontent\n````
- Export `buildGenerationPrompt(articlePlan, stylePrompt)` for single-article regeneration (used when analysis produces a plan item that needs a full article body).
- Define `PromptContext` interface: `changedFiles: Array<{ path: string; content: string }>`, `existingCategories: Array<{ id: string; name: string; slug: string; parentName?: string }>`, `existingArticles: Array<{ slug: string; title: string; categoryName: string; hasHumanEdits: boolean }>`, `analysisPrompt: string`, `articleStylePrompt: string`.
- CRITICAL per project decision: The prompt MUST include explicit instructions for the AI to prefer existing categories over creating new ones. Add text: "You MUST use an existing category unless no existing category fits. Creating a new category requires justification in the change_summary."
  </action>
  <verify>
`npx tsc --noEmit` passes. Verify imports resolve: `ai`, `@openrouter/ai-sdk-provider`, `zod/v4`, `@/lib/settings`. Check that `analysisResponseSchema.parse({...})` works with a sample object in a quick test.
  </verify>
  <done>
Three files exist with correct exports. `getAIModel()` reads from settings. Schema validates structured AI output shape. Prompt builder produces a complete prompt string with category tree, article index, style instructions, and file contents.
  </done>
</task>

<task type="auto">
  <name>Task 2: File content fetching and AI analysis + generation</name>
  <files>src/lib/ai/analyze.ts, src/lib/ai/generate.ts</files>
  <action>
**src/lib/ai/analyze.ts** -- Code analysis module:
- Export `fetchFileContents(filePaths: string[]): Promise<Array<{ path: string; content: string }>>`:
  - Use `getOctokit()` and `getRepoConfig()` from `@/lib/github/client` (existing Phase 2 code).
  - For each file path, call `octokit.repos.getContent({ owner, repo, path, ref: branch })`.
  - Decode base64 content: `Buffer.from(data.content, "base64").toString("utf-8")`.
  - Handle 404 (file deleted) by skipping silently. Handle non-file responses (arrays/directories) by skipping.
  - Respect the 1MB GitHub API limit -- files with `data.size > 1_000_000` should be skipped with a console.warn.
  - Batch fetches with concurrency limit of 5 (`Promise.all` on chunks of 5) to avoid rate limiting.
  - Reuse the `withRetry` pattern from `@/lib/github/sync` -- extract it to a shared utility OR inline a similar retry pattern. (Prefer extracting to `src/lib/github/retry.ts` if it can be done cleanly, otherwise duplicate the 10-line helper.)

- Export `analyzeChanges(fileContents, categories, articles, analysisPrompt, stylePrompt): Promise<AnalysisResponse>`:
  - Build the prompt via `buildAnalysisPrompt()`.
  - Call `generateText()` from `ai` with `output: Output.object({ schema: analysisResponseSchema })` and `model: await getAIModel()`.
  - Batch files into groups of ~25 files or ~50K characters per LLM call. For batches >1, merge the article arrays from each batch response (deduplicate by slug, prefer later batches for updates).
  - Return the parsed `AnalysisResponse`.

- Export `getFullCategoryTree(): Promise<Array<{ id, name, slug, parentName? }>>`:
  - Query `categories` table with a self-join to get parent category name.
  - Return sorted by sortOrder.

- Export `getArticleIndex(): Promise<Array<{ slug, title, categoryName, hasHumanEdits }>>`:
  - Query `articles` table joined with `categories` on categoryId.
  - Return all articles with their category names.

**src/lib/ai/generate.ts** -- Article generation for individual articles:
- Export `generateArticle(articlePlan: AnalysisResponse["articles"][0], stylePrompt: string): Promise<{ contentMarkdown: string; technicalViewMarkdown: string }>`:
  - If the analysis already provided `content_markdown` and `technical_view_markdown` with substantial content (length > 100 chars), return them directly (no second LLM call needed).
  - Otherwise, call `generateText()` with `getAIModel()` to produce the full article body using `buildGenerationPrompt()`.
  - This handles cases where the analysis step produced a plan but deferred full content generation.
  </action>
  <verify>
`npx tsc --noEmit` passes. All exports resolve. `fetchFileContents` correctly imports from `@/lib/github/client`. `analyzeChanges` correctly uses `generateText` + `Output.object` from `ai` package.
  </verify>
  <done>
`analyzeChanges()` can take file contents + category context and return a structured `AnalysisResponse` via OpenRouter. `fetchFileContents()` retrieves actual file content from GitHub. `getFullCategoryTree()` and `getArticleIndex()` query the DB for context assembly. `generateArticle()` can produce full article content from a plan item.
  </done>
</task>

</tasks>

<verification>
- `npm run build` succeeds (no type errors in new files)
- All 5 files exist under `src/lib/ai/`
- `getAIModel()` reads from site_settings (not hardcoded)
- `analysisResponseSchema` validates the expected JSON structure
- `buildAnalysisPrompt()` includes category tree, article index, style prompt, and file contents
- `fetchFileContents()` uses Octokit to fetch real file content with base64 decoding
- `analyzeChanges()` uses Vercel AI SDK `generateText` + `Output.object` (NOT deprecated `generateObject`)
</verification>

<success_criteria>
The AI foundation layer is complete: client, schemas, prompts, analysis, and generation modules all exist with proper types and exports. An executor could call `analyzeChanges(fileContents, categories, articles, prompt, style)` and receive a structured plan of articles to create/update.
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-processing-pipeline/03-01-SUMMARY.md`
</output>
